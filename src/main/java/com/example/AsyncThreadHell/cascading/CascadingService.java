package com.example.AsyncThreadHell.cascading;

import com.example.AsyncThreadHell.AsyncThreadHellApplication;
import org.jobrunr.jobs.JobId;
import org.jobrunr.jobs.annotations.Job;
import org.jobrunr.jobs.context.JobContext;
import org.jobrunr.jobs.context.JobDashboardProgressBar;
import org.jobrunr.jobs.context.JobRunrDashboardLogger;
import org.jobrunr.scheduling.JobScheduler;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import org.springframework.stereotype.Service;

import java.util.List;

@Service
public class CascadingService {

    private static Logger logger = new JobRunrDashboardLogger(LoggerFactory.getLogger(AsyncThreadHellApplication.class));

    @Value("${com.example.AsyncThreadHell.total-sub-tasks}")
    private int defaultTotalSubTasks;

    @Value("${spring.task.execution.pool.max-size}")
    private int defaultMaxConcurrentThreads;

    @Value("${com.example.AsyncThreadHell.jobrunr-refresh-seconds}")
    private int jobRunrRefreshSeconds;

    @Autowired
    private CascadingJobRepository jobRepository;

    @Autowired
    private JobScheduler jobScheduler;

    public CascadingService(JobScheduler jobScheduler) { }

    public Long enqueueMasterJob(CascadingRequest request) {

        // create and persist a job with unique runID (JobStatus.CREATED)
        replaceEmptyRequestFieldsWithDefaultsFromConfiguration(request);
        CascadingMasterJob masterJob = new CascadingMasterJob(request);
        jobRepository.save(masterJob);

        // enqueue new master job and update jobID generated by JobRunr (JobStatus.QUEUED)
        JobId jobId = jobScheduler.enqueue(() -> executeMasterJobWithConcurrentSlaveJobs(masterJob.getRunID(), masterJob.getJobDescription(), JobContext.Null));
        masterJob.setJobID(jobId.toString());
        jobRepository.save(masterJob);

        // log and return runID
        logger.info("[INFO] Service enqueued new master job (JobRunr) with runID= {}", masterJob.getRunID());
        return masterJob.getRunID();
    }

    @Job(name = "%1") // %1 lets JobRunr show the job description
    public void executeMasterJobWithConcurrentSlaveJobs(Long runID, String jobDescription, JobContext jobContext) {

        // return error message if job does not exist
        if(!jobRepository.findById(runID).isPresent()) {
            logger.error("[ERROR] Service (JobRunr) failed spawning async subtasks for {}", runID);
            return;
        }

        // get the master job and create new taskExecutor for its subtasks
        CascadingMasterJob masterJob = jobRepository.findById(runID).get();
        ThreadPoolTaskExecutor taskExecutor = getAsyncExecutor(masterJob.getRunID(), masterJob.getMaxConcurrentThreads());

        // enqueue subtasks with taskExecutor working on them concurrently (with max concurrent threads as specified)
        logger.info("[INFO] Service (JobRunr) starts spawning async subtasks for {}", masterJob.getRunID());
        for(int i=0; i<masterJob.getTotalSubTasks(); i++)
            taskExecutor.execute(new CascadingSlaveJob(masterJob.getRunID() + "." + i));
        logger.info("[INFO] Service (JobRunr) finished spawning async subtasks for {}", masterJob.getRunID());

        // keep the job running until all subtask are done
        JobDashboardProgressBar progressBar = jobContext.progressBar(100);
        masterJob.setJobStatus(CascadingMasterJob.JobStatus.RUNNING);
        do {
            // update master job and persist changed state
            masterJob.setRunningSubTasks(taskExecutor.getActiveCount());
            masterJob.setQueuedSubTasks(taskExecutor.getQueueSize());
            jobRepository.save(masterJob);

            // Update progress bar and log status in JobRunr Dashboard
            progressBar.setValue(masterJob.getProgressInPercent());
            logger.info("[INFO] Service finds run {} with {}% and {} active jobs plus {} in the queue",
                    masterJob.getRunID(),
                    masterJob.getProgressInPercent(),
                    masterJob.getRunningSubTasks(),
                    masterJob.getQueuedSubTasks());

            try { // wait for some time
                Thread.sleep(jobRunrRefreshSeconds * 1000);
            } catch (InterruptedException e) {
                logger.info("[INFO] Service caught exception during Thread.sleep()");
            }
        }
        while( masterJob.getRemainingJobs() > 0 );

        // log and persist finished state
        masterJob.setJobStatus(CascadingMasterJob.JobStatus.FINISHED);
        masterJob.setRunningSubTasks(taskExecutor.getActiveCount());
        masterJob.setQueuedSubTasks(taskExecutor.getQueueSize());
        jobRepository.save(masterJob);
        logger.info("[INFO] Service (JobRunr) finished {} including all subtasks", masterJob.getRunID());
    }

    public CascadingMasterJob getMasterJob(Long runID) {
        CascadingMasterJob job = jobRepository.findById(runID).get();
        if(job != null) {
            logger.info("[INFO] Service returns the master job with runID= {}", runID);
            return job;
        }
        else {
            logger.info("[INFO] Service can't find any runID= {}", runID);
            return null;
        }
    }

    public List<CascadingMasterJob> getAllMasterJobs() {
        return jobRepository.findAll(); // jobMap.values().stream().toList();
    }

    // ToDo: replace with proper repository query
    public List<CascadingMasterJob> getRunningMasterJobs() {
        return jobRepository.findAll()
                .stream()
                .filter( m -> m.getJobStatus() == CascadingMasterJob.JobStatus.RUNNING)
                .toList();
    }

    private ThreadPoolTaskExecutor getAsyncExecutor(Long runID, int threadCount) {
        String myExecutorName = "ServiceExecutorPool."+runID;
        logger.info("[INFO] Initialize {} (ThreadPoolTaskExecutor) with pool size = {}", myExecutorName, threadCount);
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setThreadNamePrefix(myExecutorName + "-");
        executor.setCorePoolSize(threadCount);     //default: 1
        executor.setMaxPoolSize(threadCount);      // default: Integer.MAX_VALUE
        //executor.setQueueCapacity(500);       // default: Integer.MAX_VALUE
        //executor.setKeepAliveSeconds(120);    // default: 60 seconds
        executor.initialize();
        return executor;
    }

    private void replaceEmptyRequestFieldsWithDefaultsFromConfiguration(CascadingRequest request) {
        // get default total sub tasks from config
        int totalSubTasks = request.getTotalSubTasks() != 0 ? request.getTotalSubTasks() : defaultTotalSubTasks;
        request.setTotalSubTasks(totalSubTasks);

        // get default max concurrent threads from config
        int maxConcurrentThreads = request.getMaxConcurrentThreads()!=0 ? request.getMaxConcurrentThreads() : defaultMaxConcurrentThreads;
        request.setMaxConcurrentThreads(maxConcurrentThreads);

        // create default description if not existing
        String defaultDescription = String.format("Master Job (master) with %s total subtasks ", request.getTotalSubTasks());
        String description = (request.getJobDescription() != null && !request.getJobDescription().equals("string")) ? request.getJobDescription() : defaultDescription;
        request.setJobDescription(description);
    }


}
